{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "53f81c37-db45-4fdc-843c-aa8fd2a9e99d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53f81c37-db45-4fdc-843c-aa8fd2a9e99d",
        "outputId": "643b80c4-a4f5-4544-850e-523396c7a104",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: langchain_experimental in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.3.13)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.28 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.3.28)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.13 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.13)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.3)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.2.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Requirement already satisfied: faiss-cpu==1.7.4 in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: pydantic==2.9.2 in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.9.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.9.2) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.9.2) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        " # Use termcolor to make it easy to colorize the outputs.\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        " # Use termcolor to make it easy to colorize the outputs.\n",
        "!pip install termcolor > /dev/null\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install langchain_experimental\n",
        "!pip install tiktoken\n",
        "!pip install faiss-cpu==1.7.4\n",
        "!pip install pydantic==2.9.2\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List\n",
        "import math\n",
        "import faiss\n",
        "import os\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "from langchain.cache import InMemoryCache # Import InMemoryCache\n",
        "from langchain_experimental.generative_agents import GenerativeAgentMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
        "from langchain.vectorstores import FAISS\n",
        "from termcolor import colored\n",
        "from langchain_experimental.generative_agents import (\n",
        "\n",
        "    GenerativeAgent,\n",
        "    GenerativeAgentMemory,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "p_RduA0AW2FK",
      "metadata": {
        "id": "p_RduA0AW2FK"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "81824e76",
      "metadata": {
        "id": "81824e76",
        "tags": []
      },
      "outputs": [],
      "source": [
        "USER_NAME = \"Buddy\"  # The name you want to use when interviewing the agent.\n",
        "\n",
        "LLM = ChatOpenAI(max_tokens=1500)  # Can be any LLM you want."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fa3ca02",
      "metadata": {
        "id": "2fa3ca02"
      },
      "source": [
        "## Implementing Your First Generative Agent\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ee9c1a1d-c311-4f1c-8131-75fccd9025b1",
      "metadata": {
        "id": "ee9c1a1d-c311-4f1c-8131-75fccd9025b1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def create_new_memory_retriever():\n",
        "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
        "    # Define your embedding model\n",
        "    embeddings_model = OpenAIEmbeddings()\n",
        "    # Initialize the vectorstore as empty\n",
        "    embedding_size = 1536\n",
        "    index = faiss.IndexFlatL2(embedding_size)\n",
        "    # Remove relevance_score_fn or define it before this line\n",
        "    vectorstore = FAISS(\n",
        "        embeddings_model.embed_query,\n",
        "        index,\n",
        "        InMemoryDocstore({}),\n",
        "        {},\n",
        "        # relevance_score_fn=relevance_score_fn,  # Remove this line if not needed\n",
        "    )\n",
        "    return TimeWeightedVectorStoreRetriever(\n",
        "        vectorstore=vectorstore, other_score_keys=[\"importance\"], k=15\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7884f9dd-c597-4c27-8c77-1402c71bc2f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7884f9dd-c597-4c27-8c77-1402c71bc2f8",
        "outputId": "fbb5c652-50a9-420a-b6f5-8b9bf8bb2f57",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.cache import BaseCache, InMemoryCache # Import BaseCache from langchain_community\n",
        "\n",
        "cache = InMemoryCache()\n",
        "\n",
        "alexis_memory = GenerativeAgentMemory(\n",
        "    llm=LLM,\n",
        "    memory_retriever=create_new_memory_retriever(),\n",
        "    verbose=False,\n",
        "    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works,\n",
        "    cache=cache # Pass the cache here\n",
        ")\n",
        "\n",
        "# Define Alexis\n",
        "\n",
        "alexis = GenerativeAgent(\n",
        "    name=\"Alexis\",\n",
        "    age=21,\n",
        "    traits=\"curious, helpful\",\n",
        "    status=\"looking for a challenge\",\n",
        "    memory_retriever=alexis_memory.memory_retriever,\n",
        "    llm=LLM,\n",
        "    memory=alexis_memory,\n",
        ")\n",
        "\n",
        "# After initializing alexis_memory, call model_rebuild\n",
        "alexis_memory.model_rebuild()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c524d529",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c524d529",
        "outputId": "f77b07ff-bf81-4872-d382-056d565caed8",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Alexis (age: 21)\n",
            "Innate traits: curious, helpful\n",
            "Alexis is a hardworking and dedicated individual who values honesty and integrity. She is confident in her abilities and takes pride in her work. Additionally, Alexis is a team player who is always willing to help others and collaborate on projects.\n"
          ]
        }
      ],
      "source": [
        "# The current \"Summary\" of a character can't be made because the agent hasn't made\n",
        "# any observations yet.\n",
        "print(alexis.get_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4be60979-d56e-4abf-a636-b34ffa8b7fba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4be60979-d56e-4abf-a636-b34ffa8b7fba",
        "outputId": "804132c6-9e6b-47c5-8ef0-47afb9991c24",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Alexis (age: 21)\n",
            "Innate traits: curious, helpful\n",
            "Alexis is reflective, goal-oriented, adventurous, appreciative of nature and art, and enjoys learning and trying new things.\n"
          ]
        }
      ],
      "source": [
        "# We can add memories directly to the memory object\n",
        "\n",
        "alexis_observations = [\n",
        "    \"Alexis recalls her morning walk in the park\",\n",
        "    \"Alexis feels excited about the new book she started reading\",\n",
        "    \"Alexis remembers her conversation with a close friend\",\n",
        "    \"Alexis thinks about the painting she saw at the art gallery\",\n",
        "    \"Alexis is planning to learn a new recipe for dinner\",\n",
        "    \"Alexis is looking forward to her weekend trip\",\n",
        "    \"Alexis contemplates her goals for the month.\"\n",
        "]\n",
        "\n",
        "for observation in alexis_observations:\n",
        "    alexis.memory.add_memory(observation)\n",
        "\n",
        "\n",
        "\n",
        "# We will see how this summary updates after more observations to create a more rich description.\n",
        "print(alexis.get_summary(force_refresh=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Pr2_MJggZcve",
      "metadata": {
        "id": "Pr2_MJggZcve"
      },
      "source": [
        "## Interacting and Providing Context to Generative Characters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d39a32-838c-4a03-8b27-a52c76c402e7",
      "metadata": {
        "id": "40d39a32-838c-4a03-8b27-a52c76c402e7",
        "tags": []
      },
      "source": [
        "## Pre-Interview with Character\n",
        "\n",
        "Before sending our character on their way, let's ask them a few questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "eaf125d8-f54c-4c5f-b6af-32789b1f7d3a",
      "metadata": {
        "id": "eaf125d8-f54c-4c5f-b6af-32789b1f7d3a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def interview_agent(agent: GenerativeAgent, message: str) -> str:\n",
        "    \"\"\"Help the notebook user interact with the agent.\"\"\"\n",
        "    new_message = f\"{USER_NAME} says {message}\"\n",
        "    return agent.generate_dialogue_response(new_message)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "54024d41-6e83-4914-91e5-73140e2dd9c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "54024d41-6e83-4914-91e5-73140e2dd9c8",
        "outputId": "5f5a0fcd-7395-4c85-c11b-8e9f7590c5ef",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Alexis said \"I enjoy reading, trying new recipes, going on adventures, and appreciating nature and art. How about you, Buddy?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "interview_agent(alexis, \"What do you like to do?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e509c468-f7cd-4d72-9f3a-f4aba28b1eea",
      "metadata": {
        "id": "e509c468-f7cd-4d72-9f3a-f4aba28b1eea"
      },
      "source": [
        "## Step through the day's observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "154dee3d-bfe0-4828-b963-ed7e885799b3",
      "metadata": {
        "id": "154dee3d-bfe0-4828-b963-ed7e885799b3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Let's give Alexis a series of observations to reflect on her day\n",
        "# Adding observations to Alexis' memory\n",
        "alexis_observations_day = [\n",
        "    \"Alexis starts her day with a refreshing yoga session.\",\n",
        "    \"Alexis spends time writing in her journal.\",\n",
        "    \"Alexis experiments with a new recipe she found online.\",\n",
        "    \"Alexis gets lost in her thoughts while gardening.\",\n",
        "    \"Alexis decides to call her grandmother for a heartfelt chat.\",\n",
        "    \"Alexis relaxes in the evening by playing her favorite piano pieces.\",\n",
        "]\n",
        "\n",
        "for observation in alexis_observations_day:\n",
        "    alexis.memory.add_memory(observation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "238be49c-edb3-4e26-a2b6-98777ba8de86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "238be49c-edb3-4e26-a2b6-98777ba8de86",
        "outputId": "51061399-e17d-4478-e9ba-833fb9574607",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alexis starts her day with a refreshing yoga session. Alexis smiles and feels grateful for starting her day on a positive note.\n",
            "Alexis spends time writing in her journal. Alexis feels a sense of calm and satisfaction as she reflects on her thoughts and experiences in her journal.\n",
            "Alexis experiments with a new recipe she found online. Alexis feels proud of herself for trying something new and looks forward to tasting the finished dish.\n",
            "Alexis gets lost in her thoughts while gardening. Alexis feels a sense of peace and connection with nature as she loses herself in her thoughts while gardening.\n",
            "Alexis decides to call her grandmother for a heartfelt chat. Alexis smiles and feels grateful for the opportunity to connect with her grandmother.\n",
            "Alexis relaxes in the evening by playing her favorite piano pieces. Alexis feels a sense of peace and joy as she plays her favorite piano pieces.\n",
            "****************************************\n",
            "After these observations, Alexis's summary is:\n",
            "Name: Alexis (age: 21)\n",
            "Innate traits: curious, helpful\n",
            "Alexis is reflective, creative, family-oriented, and enjoys activities that bring her peace and joy such as gardening, playing the piano, yoga, journaling, trying new things, and connecting with loved ones.\n",
            "****************************************\n"
          ]
        }
      ],
      "source": [
        "# Let's observe how Alexis's day influences her memory and character\n",
        "for i, observation in enumerate(alexis_observations_day):\n",
        "    _, reaction = alexis.generate_reaction(observation)\n",
        "    print(colored(observation, \"green\"), reaction)\n",
        "    if ((i + 1) % len(alexis_observations_day)) == 0:\n",
        "        print(\"*\" * 40)\n",
        "        print(\n",
        "            colored(\n",
        "                f\"After these observations, Alexis's summary is:\\n{alexis.get_summary(force_refresh=True)}\",\n",
        "                \"blue\",\n",
        "            )\n",
        "        )\n",
        "        print(\"*\" * 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Multiple Characters"
      ],
      "metadata": {
        "id": "xMIw8W4aaJpn"
      },
      "id": "xMIw8W4aaJpn"
    },
    {
      "cell_type": "code",
      "source": [
        "cache = InMemoryCache()\n",
        "\n",
        "henry_memory = GenerativeAgentMemory(\n",
        "    llm=LLM,\n",
        "    memory_retriever=create_new_memory_retriever(),\n",
        "    verbose=False,\n",
        "    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works,\n",
        "    cache=cache # Pass the cache here\n",
        ")\n",
        "\n",
        "# Define Henry\n",
        "\n",
        "henry = GenerativeAgent(\n",
        "    name=\"Henry\",\n",
        "    age=21,\n",
        "    traits=\"curious, helpful\",\n",
        "    status=\"looking for a challenge\",\n",
        "    memory_retriever=henry_memory.memory_retriever,\n",
        "    llm=LLM,\n",
        "    memory=henry_memory,\n",
        ")\n",
        "\n",
        "# After initializing alexis_memory, call model_rebuild\n",
        "henry_memory.model_rebuild()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfxkGWKcWeAM",
        "outputId": "953057c6-b7db-4103-edb2-72bf63356ab5"
      },
      "id": "qfxkGWKcWeAM",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define\n",
        "henry = GenerativeAgent(\n",
        "    name=\"Henry\",\n",
        "    age=35,\n",
        "    traits=\"gamer, foodie, tech guy\",\n",
        "    status=\"wants to work in startups \",\n",
        "    memory_retriever=henry_memory.memory_retriever,\n",
        "    llm=LLM,\n",
        "    memory=henry_memory,\n",
        ")"
      ],
      "metadata": {
        "id": "EcqjFto03G35"
      },
      "id": "EcqjFto03G35",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding observations to Henry's Memories\n",
        "\n",
        "henry_observations_day = [\n",
        "\n",
        "    \"Henry finished a challenging coding project last night\",\n",
        "    \"Henry won a local gaming tournament over the weekend\",\n",
        "    \"Henry tried a new sushi restaurant and loved it\",\n",
        "    \"Henry read an article about the latest AI advancements\",\n",
        "    \"Henry is planning a meetup with tech enthusiasts\",\n",
        "    \"Henry discovered a bug in his latest app prototype\",\n",
        "    \"Henry booked tickets for a tech conference next month\",\n",
        "    \"Henry feels excited about a potential startup idea\",\n",
        "    \"Henry spent the evening playing video games to unwind\",\n",
        "    \"Henry is considering enrolling in a machine learning course\"\n",
        "\n",
        "]\n",
        "\n",
        "for observation in henry_observations_day:\n",
        "  henry.memory.add_memory(observation)\n",
        "\n",
        "print(henry.get_summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK97Wqpz3XKy",
        "outputId": "d3fb10ed-f60a-442a-90f5-ce3672c24f51"
      },
      "id": "mK97Wqpz3XKy",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Henry (age: 35)\n",
            "Innate traits: gamer, foodie, tech guy\n",
            "Henry is a tech-savvy individual who is passionate about startups, gaming, coding, machine learning, and AI advancements. He is social and enjoys connecting with other tech enthusiasts, but also values relaxation and trying new experiences like new restaurants.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dialogue between Generative Agents"
      ],
      "metadata": {
        "id": "yK2eSw3U5k7M"
      },
      "id": "yK2eSw3U5k7M"
    },
    {
      "cell_type": "code",
      "source": [
        "#Define conversations for agents to interact\n",
        "\n",
        "def run_conversation(agents: List[GenerativeAgent], initial_observation: str) -> None:\n",
        "    \"\"\"Runs a conversation between agents.\"\"\"\n",
        "    _, observation = agents[1].generate_reaction(initial_observation)\n",
        "    print(observation)\n",
        "    max_turns = 3\n",
        "    turns = 0\n",
        "    while turns<=max_turns:\n",
        "        break_dialogue = False\n",
        "        for agent in agents:\n",
        "            stay_in_dialogue, observation = agent.generate_dialogue_response(\n",
        "                observation\n",
        "            )\n",
        "            print(observation)\n",
        "            # observation = f\"{agent.name} said {reaction}\"\n",
        "            if not stay_in_dialogue:\n",
        "                break_dialogue = True\n",
        "        if break_dialogue:\n",
        "            break\n",
        "        turns += 1"
      ],
      "metadata": {
        "id": "Bt57vIaj5ZAa"
      },
      "id": "Bt57vIaj5ZAa",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agents = [alexis, henry]\n",
        "run_conversation(agents,\n",
        "                 \"Alexis said: Hi, Henry how are you? I have been exploring how technology influences creativity. Since you are into tech, what do you think about this? \"\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqlYAGoP9DVM",
        "outputId": "89b52899-63bc-457e-9d04-9a53c732cfb5"
      },
      "id": "sqlYAGoP9DVM",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Henry said \"I think technology can definitely enhance creativity by providing new tools and platforms for expression.\"\n",
            "Alexis said \"I agree, Henry. Technology has opened up so many possibilities for creativity. Have you tried any new creative tools or platforms recently?\"\n",
            "Henry said \"Yes, I've been experimenting with some new design software tools lately. It's amazing how technology can really push the boundaries of creativity.\"\n",
            "Alexis said \"That's so cool, Henry! Technology really does open up a whole new world of possibilities. I'm glad you're exploring new tools and pushing your creativity. Have you seen any particular improvements in your design work since using the new software?\"\n",
            "Henry said \"Thanks, Alexis! I've definitely noticed an improvement in my design work. The new software has helped me streamline my process and create more polished designs. Have you tried any new tools or platforms that have had a similar impact on your work?\"\n",
            "Alexis said \"That's great to hear, Henry! I haven't tried any new tools recently, but I'm always open to exploring different platforms to enhance my creativity. It's inspiring to see how technology can really elevate our work. Thank you for sharing your experience with me.\"\n",
            "Henry said \"Thank you, Alexis! I'm glad we can share our experiences and insights on technology and creativity. It's always great to bounce ideas off each other and learn from each other's journeys. Have a great day!\"\n",
            "Alexis said \"Thank you, Henry! I agree, it's wonderful to have someone to bounce ideas off of and learn from. Have a great day too!\"\n",
            "Henry said \"It's always great chatting with you, Alexis! Let's catch up soon. Have a fantastic day!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets see how the conversation went between the two agents"
      ],
      "metadata": {
        "id": "Qi5NHACk9ln0"
      },
      "id": "Qi5NHACk9ln0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Alexis\n",
        "interview_agent(alexis, \"How was your covnersation with Henry?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "KKlF2YkO9Ebm",
        "outputId": "2ad5aa5c-48d9-4d57-8fec-bce8bf963562"
      },
      "id": "KKlF2YkO9Ebm",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Alexis said \"My conversation with Henry was great! We talked about technology, creativity, and how it can enhance our work. It was really inspiring. How about you, Buddy? Have you had any interesting conversations lately?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(henry, \"How was your conversation with Alexis?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p8mAAS4N9EZI",
        "outputId": "1f0c98de-eb87-4f85-9794-36625fac3178"
      },
      "id": "p8mAAS4N9EZI",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Henry said \"It was great! We always have such interesting discussions about technology and creativity. Alexis is always so insightful and supportive.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------"
      ],
      "metadata": {
        "id": "eFQ3tv6eAmjN"
      },
      "id": "eFQ3tv6eAmjN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dialogue Agent and Dialogue Simulator Classes\n",
        "\n",
        "This approach chooses the next speaker and passes thier message to all agents and updates the conversation state."
      ],
      "metadata": {
        "id": "NQ5A8nDuAoHj"
      },
      "id": "NQ5A8nDuAoHj"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, List\n",
        "import tenacity\n",
        "from langchain.schema import (\n",
        "    HumanMessage,\n",
        "    SystemMessage,\n",
        ")"
      ],
      "metadata": {
        "id": "kVpPdt-hDjvh"
      },
      "id": "kVpPdt-hDjvh",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DialogueAgent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        system_message: SystemMessage,\n",
        "        model: ChatOpenAI,\n",
        "    ) -> None:\n",
        "        self.name = name\n",
        "        self.system_message = system_message\n",
        "        self.model = model\n",
        "        self.prefix = f\"{self.name}: \"\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.message_history = [\"Here is the conversation so far.\"]\n",
        "\n",
        "    def send(self) -> str:\n",
        "        \"\"\"\n",
        "        Applies the chatmodel to the message history\n",
        "        and returns the message string\n",
        "        \"\"\"\n",
        "        message = self.model(\n",
        "            [\n",
        "                self.system_message,\n",
        "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
        "            ]\n",
        "        )\n",
        "        return message.content\n",
        "\n",
        "    def receive(self, name: str, message: str) -> None:\n",
        "        \"\"\"\n",
        "        Concatenates {message} spoken by {name} into message history\n",
        "        \"\"\"\n",
        "        self.message_history.append(f\"{name}: {message}\")\n",
        "\n",
        "\n",
        "class DialogueSimulator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        agents: List[DialogueAgent],\n",
        "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
        "    ) -> None:\n",
        "        self.agents = agents\n",
        "        self._step = 0\n",
        "        self.select_next_speaker = selection_function\n",
        "\n",
        "    def reset(self):\n",
        "        for agent in self.agents:\n",
        "            agent.reset()\n",
        "\n",
        "    def inject(self, name: str, message: str):\n",
        "        \"\"\"\n",
        "        Initiates the conversation with a {message} from {name}\n",
        "        \"\"\"\n",
        "        for agent in self.agents:\n",
        "            agent.receive(name, message)\n",
        "\n",
        "        # increment time\n",
        "        self._step += 1\n",
        "\n",
        "    def step(self) -> tuple[str, str]:\n",
        "        # 1. choose the next speaker\n",
        "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
        "        speaker = self.agents[speaker_idx]\n",
        "\n",
        "        # 2. next speaker sends message\n",
        "        message = speaker.send()\n",
        "\n",
        "        # 3. everyone receives message\n",
        "        for receiver in self.agents:\n",
        "            receiver.receive(speaker.name, message)\n",
        "\n",
        "        # 4. increment time\n",
        "        self._step += 1\n",
        "\n",
        "        return speaker.name, message"
      ],
      "metadata": {
        "id": "sqqZAxW79EUW"
      },
      "id": "sqqZAxW79EUW",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bidding Dialogue Agent class"
      ],
      "metadata": {
        "id": "qvHSUs9AEFNX"
      },
      "id": "qvHSUs9AEFNX"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "IQlgr-M5HAYQ"
      },
      "id": "IQlgr-M5HAYQ",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiddingDialogueAgent(DialogueAgent):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name,\n",
        "        system_message: SystemMessage,\n",
        "        bidding_template: PromptTemplate,\n",
        "        model: ChatOpenAI,\n",
        "    ) -> None:\n",
        "        super().__init__(name, system_message, model)\n",
        "        self.bidding_template = bidding_template\n",
        "\n",
        "    def bid(self) -> str:\n",
        "        \"\"\"\n",
        "        Asks the chat model to output a bid to speak\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate(\n",
        "            input_variables=[\"message_history\", \"recent_message\"],\n",
        "            template=self.bidding_template,\n",
        "        ).format(\n",
        "            message_history=\"\\n\".join(self.message_history),\n",
        "            recent_message=self.message_history[-1],\n",
        "        )\n",
        "        bid_string = self.model([SystemMessage(content=prompt)]).content\n",
        "        return bid_string"
      ],
      "metadata": {
        "id": "dU6fUnxR9ER6"
      },
      "id": "dU6fUnxR9ER6",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9uBF_Kgr9EPW"
      },
      "id": "9uBF_Kgr9EPW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5r3Dbu3z9EMg"
      },
      "id": "5r3Dbu3z9EMg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GDWwoezv9EGU"
      },
      "id": "GDWwoezv9EGU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}